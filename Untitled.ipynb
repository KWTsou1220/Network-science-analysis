{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from utils import read_train_data, read_test_data\n",
    "from utils import extract_features\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import time\n",
    "import math\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "train_data_path = './Dataset/training_set.txt'\n",
    "test_data_path = './Dataset/testing_set.txt'\n",
    "G, node_pairs_train, t_train = read_train_data(train_data_path)\n",
    "node_pairs_test = read_test_data(test_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In nodes of  9510123\n",
      "[9806213, 9903054, 9610031]\n",
      "[9408144, 9502114, 9302075]\n"
     ]
    }
   ],
   "source": [
    "print('In nodes of ', node_pairs_train[0, 0])\n",
    "print(G.predecessors(node_pairs_train[0, 0])) # in nodes\n",
    "print(G.successors(node_pairs_train[0, 0])) # out nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_text_dict(path):\n",
    "    node_info = {}\n",
    "    with open(path, encoding='utf8') as f:\n",
    "        for line in f:\n",
    "            info = line.split(',')\n",
    "            _id = int(info[0])\n",
    "            year = int(info[1])\n",
    "            title = info[2]\n",
    "            title = set(title.split(' '))\n",
    "            authors = info[3:-2]\n",
    "            authors = set([author.replace('\"', '').replace(' ', '') for author in authors])\n",
    "            journal = info[-2]\n",
    "            abstract = info[-1][0:-1]\n",
    "            abstract = set(abstract.split(' '))\n",
    "            node_info[_id] = [year, title, authors, journal, abstract]\n",
    "    return node_info\n",
    "    # 0: public year\n",
    "    # 1: title\n",
    "    # 2: authors\n",
    "    # 3: name of journal\n",
    "    # 4: abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "node_info = build_text_dict('./Dataset/node_information.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2000,\n",
       " {'and', 'compactification', 'duality', 'geometry'},\n",
       " {'PaulS.Aspinwall'},\n",
       " '',\n",
       " {'2',\n",
       "  'a',\n",
       "  'and',\n",
       "  'are',\n",
       "  'as',\n",
       "  'at',\n",
       "  'attention',\n",
       "  'based',\n",
       "  'between',\n",
       "  'by',\n",
       "  'calabi-yau',\n",
       "  'case',\n",
       "  'cases',\n",
       "  'compactification',\n",
       "  'compactified',\n",
       "  'considered',\n",
       "  'current',\n",
       "  'detail',\n",
       "  'differences',\n",
       "  'dimensions',\n",
       "  'discussed',\n",
       "  'each',\n",
       "  'four',\n",
       "  'from',\n",
       "  'geometry',\n",
       "  'given',\n",
       "  'heterotic',\n",
       "  'hypermultiplet',\n",
       "  'hypermultiplets',\n",
       "  'iia',\n",
       "  'iib',\n",
       "  'in',\n",
       "  'instantons',\n",
       "  'is',\n",
       "  'k3xt2',\n",
       "  'lectures',\n",
       "  'limited',\n",
       "  'mixed',\n",
       "  'moduli',\n",
       "  'multiplets',\n",
       "  'n',\n",
       "  'non-existence',\n",
       "  'notes',\n",
       "  'of',\n",
       "  'on',\n",
       "  'or',\n",
       "  'our',\n",
       "  'pay',\n",
       "  'peculiarities',\n",
       "  'point',\n",
       "  'poor',\n",
       "  'review',\n",
       "  'reviewed',\n",
       "  'some',\n",
       "  'space',\n",
       "  'spaces',\n",
       "  'specific',\n",
       "  'state',\n",
       "  'string',\n",
       "  'such',\n",
       "  'superstring',\n",
       "  'tasi99',\n",
       "  'the',\n",
       "  'theories',\n",
       "  'these',\n",
       "  'this',\n",
       "  'threefold',\n",
       "  'to',\n",
       "  'type',\n",
       "  'understanding',\n",
       "  'universal',\n",
       "  'vector',\n",
       "  'view',\n",
       "  'we'}]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_info[1001]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
